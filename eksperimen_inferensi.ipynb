{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_4569/3135097857.py:1: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator SVC from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_4569/3135097857.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
    "tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraperKey(keyword,date_since,date_until):\n",
    "    query = keyword+\" lang:id until:\"+str(date_until)+\" since:\"+str(date_since)\n",
    "    #print(query)\n",
    "    #print(datetime.now())\n",
    "    #print(\"Sedang Mengumpulkan Data Twitter...\")\n",
    "    tweets = []\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "        tweets.append([tweet.date, tweet.user.username, tweet.content, tweet.hashtags, tweet.likeCount, tweet.retweetCount, tweet.replyCount])\n",
    "        \n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet', 'Hashtags', 'Like', 'Retweet', 'Reply'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode() #remove emojis\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
    "    text = word_tokenize(text) \n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Remove stopwors in a text\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    text = [w for w in text if not w in listStopwords]\n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    #factory = StemmerFactory()\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n",
    "\n",
    "alay_dict = pd.read_csv('colloquial-indonesian-lexicon.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', 1: 'replacement'})\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "\n",
    "def normalize_alay(text):\n",
    " text = ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    " text = re.sub(' +', ' ', text)\n",
    " return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraperKey('pemilu','2022-12-15','2022-12-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Like</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-17 23:59:55+00:00</td>\n",
       "      <td>syahidun58</td>\n",
       "      <td>@HelmiFelis_ Beliau tidak mau berseteru dengan...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-17 23:58:49+00:00</td>\n",
       "      <td>PKS_Bojongmangu</td>\n",
       "      <td>Kembali Dapat Nomor Urut 8 di Pemilu 2024, PKS...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-17 23:58:35+00:00</td>\n",
       "      <td>PKS_Bojongmangu</td>\n",
       "      <td>PKS Tekankan Pemilu 2024 Harus Jujur dan Adil ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-17 23:58:33+00:00</td>\n",
       "      <td>PKS_Bojongmangu</td>\n",
       "      <td>Dapat Nomor Urut 8, Presiden PKS: Mari Kita Ka...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-17 23:57:58+00:00</td>\n",
       "      <td>dedypr_</td>\n",
       "      <td>Bukanya knp knp ya, stiap menjelang pemilu lih...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date             User  \\\n",
       "0 2022-12-17 23:59:55+00:00       syahidun58   \n",
       "1 2022-12-17 23:58:49+00:00  PKS_Bojongmangu   \n",
       "2 2022-12-17 23:58:35+00:00  PKS_Bojongmangu   \n",
       "3 2022-12-17 23:58:33+00:00  PKS_Bojongmangu   \n",
       "4 2022-12-17 23:57:58+00:00          dedypr_   \n",
       "\n",
       "                                               Tweet Hashtags  Like  Retweet  \\\n",
       "0  @HelmiFelis_ Beliau tidak mau berseteru dengan...     None     0        0   \n",
       "1  Kembali Dapat Nomor Urut 8 di Pemilu 2024, PKS...     None     0        0   \n",
       "2  PKS Tekankan Pemilu 2024 Harus Jujur dan Adil ...     None     0        0   \n",
       "3  Dapat Nomor Urut 8, Presiden PKS: Mari Kita Ka...     None     0        0   \n",
       "4  Bukanya knp knp ya, stiap menjelang pemilu lih...     None     0        0   \n",
       "\n",
       "   Reply  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang Membersihkan Data Twitter...\n",
      "2023-01-10 13:42:32.588856\n",
      "cleaning text\n",
      "2023-01-10 13:42:32.688312\n",
      "casefolding text\n",
      "2023-01-10 13:42:32.764661\n",
      "tokenizing text\n",
      "2023-01-10 13:42:33.635552\n",
      "filtering text\n",
      "2023-01-10 13:42:35.874592\n",
      "stemming text\n",
      "Selesai Membersihkan Data Twitter :)\n",
      "2023-01-10 13:42:37.518494\n",
      "                          Date             User  \\\n",
      "0    2022-12-17 23:59:55+00:00       syahidun58   \n",
      "1    2022-12-17 23:58:49+00:00  PKS_Bojongmangu   \n",
      "2    2022-12-17 23:58:35+00:00  PKS_Bojongmangu   \n",
      "3    2022-12-17 23:58:33+00:00  PKS_Bojongmangu   \n",
      "4    2022-12-17 23:57:58+00:00          dedypr_   \n",
      "...                        ...              ...   \n",
      "9598 2022-12-15 00:00:11+00:00         ekodj373   \n",
      "9599 2022-12-15 00:00:06+00:00    toServetoGive   \n",
      "9600 2022-12-15 00:00:02+00:00        adekaka01   \n",
      "9601 2022-12-15 00:00:01+00:00   liputan6dotcom   \n",
      "9602 2022-12-15 00:00:01+00:00     WartaEkonomi   \n",
      "\n",
      "                                                  Tweet  \\\n",
      "0     @HelmiFelis_ Beliau tidak mau berseteru dengan...   \n",
      "1     Kembali Dapat Nomor Urut 8 di Pemilu 2024, PKS...   \n",
      "2     PKS Tekankan Pemilu 2024 Harus Jujur dan Adil ...   \n",
      "3     Dapat Nomor Urut 8, Presiden PKS: Mari Kita Ka...   \n",
      "4     Bukanya knp knp ya, stiap menjelang pemilu lih...   \n",
      "...                                                 ...   \n",
      "9598  @musniumar kalau sdh tdk masuk ya sdh diterima...   \n",
      "9599  @alisyarief Terzalimi adlh KATA KUNCI para pec...   \n",
      "9600  Pemilu 2024 semakin dekat dekat dan pemerintah...   \n",
      "9601  Perppu Pemilu dinilai tidak ada kebutuhan yang...   \n",
      "9602  Macam Elite Megawati, NasDem Bersyukur Sama Ke...   \n",
      "\n",
      "                                     Hashtags  Like  Retweet  Reply  \\\n",
      "0                                        None     0        0      0   \n",
      "1                                        None     0        0      0   \n",
      "2                                        None     0        0      0   \n",
      "3                                        None     0        0      0   \n",
      "4                                        None     0        0      0   \n",
      "...                                       ...   ...      ...    ...   \n",
      "9598                                     None     0        0      0   \n",
      "9599                                     None     0        0      0   \n",
      "9600  [DukungPembangunanIKN, RKUHPUntukSemua]     0        0      0   \n",
      "9601                                     None     2        0      0   \n",
      "9602                                     None     0        0      0   \n",
      "\n",
      "                                             text_clean  \\\n",
      "0     beliau tidak mau berseteru dengan zulhas terny...   \n",
      "1     kembali dapat nomor urut di pemilu pks kalsel ...   \n",
      "2              pks tekankan pemilu harus jujur dan adil   \n",
      "3     dapat nomor urut presiden pks mari kita kawal ...   \n",
      "4     bukanya kenapa kenapa ya setiap menjelang pemi...   \n",
      "...                                                 ...   \n",
      "9598  kalau sudah tidak masuk ya sudah diterima deng...   \n",
      "9599  terzalimi adalah kata kunci para pecundang ar ...   \n",
      "9600  pemilu semakin dekat dekat dan pemerintah suda...   \n",
      "9601  perppu pemilu dinilai tidak ada kebutuhan yang...   \n",
      "9602  macam elite megawati nasdem bersyukur sama ket...   \n",
      "\n",
      "                                      text_preprocessed  \n",
      "0     [beliau, berseteru, zulha, takut, kehilangan, ...  \n",
      "1            [nomor, urut, pemilu, pk, kalsel, identik]  \n",
      "2                   [pk, tekankan, pemilu, jujur, adil]  \n",
      "3     [nomor, urut, presiden, pk, mari, kawal, pemil...  \n",
      "4     [bukanya, ya, menjelang, pemilu, lihat, banner...  \n",
      "...                                                 ...  \n",
      "9598  [masuk, ya, diterima, lapang, dada, menandakan...  \n",
      "9599  [terzalimi, kunci, pecundang, ar, mendirikan, ...  \n",
      "9600  [pemilu, pemerintah, menyerahkan, daftar, juta...  \n",
      "9601  [perppu, pemilu, dinilai, kebutuhan, gent, lan...  \n",
      "9602  [elit, megawati, nasdem, bersyukur, ketentuan,...  \n",
      "\n",
      "[9488 rows x 9 columns]\n",
      "Sedang Menganalisis Sentimen Publik...\n",
      "2023-01-10 13:42:37.522188\n",
      "Selesai Menganalisis Sentimen Publik :)\n",
      "2023-01-10 13:42:41.429044\n",
      "                                             text_clean Result Prediction\n",
      "0     beliau tidak mau berseteru dengan zulhas terny...           Neutral\n",
      "1     kembali dapat nomor urut di pemilu pks kalsel ...          Positive\n",
      "2              pks tekankan pemilu harus jujur dan adil           Neutral\n",
      "3     dapat nomor urut presiden pks mari kita kawal ...          Positive\n",
      "4     bukanya kenapa kenapa ya setiap menjelang pemi...          Positive\n",
      "...                                                 ...               ...\n",
      "9598  kalau sudah tidak masuk ya sudah diterima deng...           Neutral\n",
      "9599  terzalimi adalah kata kunci para pecundang ar ...           Neutral\n",
      "9600  pemilu semakin dekat dekat dan pemerintah suda...          Positive\n",
      "9601  perppu pemilu dinilai tidak ada kebutuhan yang...          Positive\n",
      "9602  macam elite megawati nasdem bersyukur sama ket...          Positive\n",
      "\n",
      "[9488 rows x 2 columns]\n",
      "                          Date             User  \\\n",
      "0    2022-12-17 23:59:55+00:00       syahidun58   \n",
      "1    2022-12-17 23:58:49+00:00  PKS_Bojongmangu   \n",
      "2    2022-12-17 23:58:35+00:00  PKS_Bojongmangu   \n",
      "3    2022-12-17 23:58:33+00:00  PKS_Bojongmangu   \n",
      "4    2022-12-17 23:57:58+00:00          dedypr_   \n",
      "...                        ...              ...   \n",
      "9598 2022-12-15 00:00:11+00:00         ekodj373   \n",
      "9599 2022-12-15 00:00:06+00:00    toServetoGive   \n",
      "9600 2022-12-15 00:00:02+00:00        adekaka01   \n",
      "9601 2022-12-15 00:00:01+00:00   liputan6dotcom   \n",
      "9602 2022-12-15 00:00:01+00:00     WartaEkonomi   \n",
      "\n",
      "                                                  Tweet  \\\n",
      "0     @HelmiFelis_ Beliau tidak mau berseteru dengan...   \n",
      "1     Kembali Dapat Nomor Urut 8 di Pemilu 2024, PKS...   \n",
      "2     PKS Tekankan Pemilu 2024 Harus Jujur dan Adil ...   \n",
      "3     Dapat Nomor Urut 8, Presiden PKS: Mari Kita Ka...   \n",
      "4     Bukanya knp knp ya, stiap menjelang pemilu lih...   \n",
      "...                                                 ...   \n",
      "9598  @musniumar kalau sdh tdk masuk ya sdh diterima...   \n",
      "9599  @alisyarief Terzalimi adlh KATA KUNCI para pec...   \n",
      "9600  Pemilu 2024 semakin dekat dekat dan pemerintah...   \n",
      "9601  Perppu Pemilu dinilai tidak ada kebutuhan yang...   \n",
      "9602  Macam Elite Megawati, NasDem Bersyukur Sama Ke...   \n",
      "\n",
      "                                     Hashtags  Like  Retweet  Reply  \\\n",
      "0                                        None     0        0      0   \n",
      "1                                        None     0        0      0   \n",
      "2                                        None     0        0      0   \n",
      "3                                        None     0        0      0   \n",
      "4                                        None     0        0      0   \n",
      "...                                       ...   ...      ...    ...   \n",
      "9598                                     None     0        0      0   \n",
      "9599                                     None     0        0      0   \n",
      "9600  [DukungPembangunanIKN, RKUHPUntukSemua]     0        0      0   \n",
      "9601                                     None     2        0      0   \n",
      "9602                                     None     0        0      0   \n",
      "\n",
      "                                             text_clean  \\\n",
      "0     beliau tidak mau berseteru dengan zulhas terny...   \n",
      "1     kembali dapat nomor urut di pemilu pks kalsel ...   \n",
      "2              pks tekankan pemilu harus jujur dan adil   \n",
      "3     dapat nomor urut presiden pks mari kita kawal ...   \n",
      "4     bukanya kenapa kenapa ya setiap menjelang pemi...   \n",
      "...                                                 ...   \n",
      "9598  kalau sudah tidak masuk ya sudah diterima deng...   \n",
      "9599  terzalimi adalah kata kunci para pecundang ar ...   \n",
      "9600  pemilu semakin dekat dekat dan pemerintah suda...   \n",
      "9601  perppu pemilu dinilai tidak ada kebutuhan yang...   \n",
      "9602  macam elite megawati nasdem bersyukur sama ket...   \n",
      "\n",
      "                                      text_preprocessed Result Prediction  \n",
      "0     [beliau, berseteru, zulha, takut, kehilangan, ...           Neutral  \n",
      "1            [nomor, urut, pemilu, pk, kalsel, identik]          Positive  \n",
      "2                   [pk, tekankan, pemilu, jujur, adil]           Neutral  \n",
      "3     [nomor, urut, presiden, pk, mari, kawal, pemil...          Positive  \n",
      "4     [bukanya, ya, menjelang, pemilu, lihat, banner...          Positive  \n",
      "...                                                 ...               ...  \n",
      "9598  [masuk, ya, diterima, lapang, dada, menandakan...           Neutral  \n",
      "9599  [terzalimi, kunci, pecundang, ar, mendirikan, ...           Neutral  \n",
      "9600  [pemilu, pemerintah, menyerahkan, daftar, juta...          Positive  \n",
      "9601  [perppu, pemilu, dinilai, kebutuhan, gent, lan...          Positive  \n",
      "9602  [elit, megawati, nasdem, bersyukur, ketentuan,...          Positive  \n",
      "\n",
      "[9488 rows x 10 columns]\n",
      "Date                 object\n",
      "User                 object\n",
      "Tweet                object\n",
      "Hashtags             object\n",
      "Like                  int64\n",
      "Retweet               int64\n",
      "Reply                 int64\n",
      "text_clean           object\n",
      "text_preprocessed    object\n",
      "Result Prediction    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "if df.empty:\n",
    "    print(\"Tidak ada data atau query keliru!\")\n",
    "else:\n",
    "    df = df.drop_duplicates(subset=['Tweet'])\n",
    "    dataset = df\n",
    "    #print(dataset)\n",
    "    print(\"Sedang Membersihkan Data Twitter...\")\n",
    "    #gabungin hashtags\n",
    "    # dataset['Hashtags'] = '-'.join(dataset['Hashtags'])\n",
    "    print(datetime.now())\n",
    "    print('cleaning text')\n",
    "    dataset['text_clean'] = dataset['Tweet'].apply(cleaningText)\n",
    "    print(datetime.now())\n",
    "    print('casefolding text')\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(casefoldingText)\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(normalize_alay)\n",
    "    # dataset.drop(['Tweet'], axis = 1, inplace = True)\n",
    "    print(datetime.now())\n",
    "    print('tokenizing text')\n",
    "    dataset['text_preprocessed'] = dataset['text_clean'].apply(tokenizingText)\n",
    "    print(datetime.now())\n",
    "    print(\"filtering text\")\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(filteringText)\n",
    "    print(datetime.now())\n",
    "    print('stemming text')\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(stemmingText)\n",
    "    print(\"Selesai Membersihkan Data Twitter :)\")\n",
    "    print(datetime.now())\n",
    "    print(dataset)\n",
    "    cleanData = dataset\n",
    "\n",
    "        ###################################\n",
    "        ###      SENTIMENT ANALYSIS     ###\n",
    "        ###################################\n",
    "\n",
    "    print(\"Sedang Menganalisis Sentimen Publik...\")\n",
    "    print(datetime.now())\n",
    "    # Make text preprocessed (tokenized) to untokenized with toSentence Function\n",
    "    X = cleanData['text_preprocessed'].apply(toSentence)\n",
    "    X = tfidf_vectorizer.transform(X.values)\n",
    "    \n",
    "    # e = X.toarray()\n",
    "    # #rumus mean\n",
    "    # n = 0\n",
    "    # mean = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())/5000\n",
    "    #     mean.append(a)\n",
    "\n",
    "    # #standar deviasi\n",
    "    # n = 0\n",
    "    # stdev = []\n",
    "    # for i in e:\n",
    "    #     s = np.std(i.tolist())\n",
    "    #     stdev.append(s)\n",
    "\n",
    "    # #max value\n",
    "    # n = 0\n",
    "    # maks = []\n",
    "    # for i in e:\n",
    "    #     a = max(i.tolist())\n",
    "    #     maks.append(a)\n",
    "\n",
    "    # #sum\n",
    "    # n = 0\n",
    "    # summ = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())\n",
    "    #     summ.append(a)\n",
    "\n",
    "    # #count feature\n",
    "    # n = 0\n",
    "    # count = []\n",
    "    # for i in e:\n",
    "    #     a = sum(map(lambda x : x != 0, i.tolist()))\n",
    "    #     count.append(a)\n",
    "\n",
    "    # extra_X = np.column_stack((e, np.array(mean), np.array(stdev), np.array(maks), np.array(summ), np.array(count)))\n",
    "\n",
    "    # from scipy import sparse\n",
    "    # extra_X = sparse.csr_matrix(extra_X)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    cleanData['Result Prediction'] = y_pred\n",
    "\n",
    "    polarity_decode = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n",
    "    cleanData['Result Prediction'] = cleanData['Result Prediction'].map(polarity_decode)\n",
    "    print(\"Selesai Menganalisis Sentimen Publik :)\")\n",
    "    print(datetime.now())\n",
    "    print(cleanData[['text_clean','Result Prediction']])\n",
    "    #print('OK')\n",
    "    print(cleanData)\n",
    "    cleanData['Date'] = pd.to_datetime(cleanData['Date']).dt.date\n",
    "    cleanData['Date']=cleanData['Date'].astype(str)\n",
    "        \n",
    "    print(cleanData.dtypes)\n",
    "    # data_dict = cleanData.to_dict(orient='records')\n",
    "    # print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData[['Tweet', 'Result Prediction', 'text_preprocessed']].to_csv('pemilu.csv')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "872e9ac453f67b7e35588ebe4d602923bc34b4c5daddde36c325676c5fe52d29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
