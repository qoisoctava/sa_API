{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_6682/1179595794.py:1: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator SVC from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_6682/1179595794.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
    "tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))\n",
    "APIurl = 'http://127.0.0.1:3000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraperKey(keyword,date_since,date_until):\n",
    "    query = keyword+\" lang:id until:\"+str(date_until)+\" since:\"+str(date_since)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    requests.post('{}/progress/twitter/new'.format(APIurl),{'dateGet':now,'keyword':keyword,'dateSince':date_since,'dateUntil':date_until,'status':1,'source':'tw'} )\n",
    "    #print(query)\n",
    "    #print(datetime.now())\n",
    "    #print(\"Sedang Mengumpulkan Data Twitter...\")\n",
    "    tweets = []\n",
    "    while len(tweets) <= 20:\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            tweets.append([datetime.now().date(), keyword, tweet.date, tweet.user.username, tweet.content, tweet.hashtags,tweet.mentionedUsers, tweet.likeCount, tweet.retweetCount, tweet.replyCount])\n",
    "        \n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(tweets, columns=['timestamp','keyword','date', 'user', 'tweet', 'hashtags', 'mentions', 'likeCount', 'retweetCount', 'replyCount'])\n",
    "    return df,now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode() #remove emojis\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
    "    text = word_tokenize(text) \n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Remove stopwors in a text\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    text = [w for w in text if not w in listStopwords]\n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    #factory = StemmerFactory()\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n",
    "\n",
    "alay_dict = pd.read_csv('colloquial-indonesian-lexicon.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', 1: 'replacement'})\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "\n",
    "def normalize_alay(text):\n",
    " text = ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    " text = re.sub(' +', ' ', text)\n",
    " return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_6682/3958851375.py:11: FutureWarning: content is deprecated, use rawContent instead\n",
      "  tweets.append([datetime.now().date(), keyword, tweet.date, tweet.user.username, tweet.content, tweet.hashtags,tweet.mentionedUsers, tweet.likeCount, tweet.retweetCount, tweet.replyCount])\n"
     ]
    }
   ],
   "source": [
    "df, now = scraperKey('kereta cepat','2023-01-13','2023-01-18')\n",
    "topic = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-31 12:36:57'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17 23:16:06+00:00</td>\n",
       "      <td>Baekamee</td>\n",
       "      <td>@sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/sunuy_gans, https://twitt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17 22:59:48+00:00</td>\n",
       "      <td>ayuradzan</td>\n",
       "      <td>Early 18 dah dapat lesen kereta dah. kena cepa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17 22:20:03+00:00</td>\n",
       "      <td>mase_aga</td>\n",
       "      <td>@Adabapaknya1 @sunuy_gans @worksfess Kalo kere...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Adabapaknya1, https://twi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17 20:23:14+00:00</td>\n",
       "      <td>Mustafic_Khzan</td>\n",
       "      <td>Penerimaan pajak kita memang besar tapi Yang d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17 20:16:39+00:00</td>\n",
       "      <td>dsyauls</td>\n",
       "      <td>@worksfess Harusnya kereta cepat itu Jakarta -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/worksfess]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13 01:37:36+00:00</td>\n",
       "      <td>handokosupraja</td>\n",
       "      <td>@endonesiatwit @Dennysiregar7 lu tua geblek pu...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/endonesiatwit, https://tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13 01:35:11+00:00</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Kereta boleh dapat cepat ni kalau Ativa Av, At...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13 01:33:53+00:00</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Pesanan khidmat masyarakat untuk sesiapa yang ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13 00:27:01+00:00</td>\n",
       "      <td>abdul_karel</td>\n",
       "      <td>@Al4mSyahputra Krisis gara2  pinjam duit tdk p...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Al4mSyahputra]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13 00:20:27+00:00</td>\n",
       "      <td>giginpraginanto</td>\n",
       "      <td>Para pengendali di pusat kekuasaan kelihatan s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>213</td>\n",
       "      <td>105</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp       keyword                      date             user  \\\n",
       "0    2023-01-31  kereta cepat 2023-01-17 23:16:06+00:00         Baekamee   \n",
       "1    2023-01-31  kereta cepat 2023-01-17 22:59:48+00:00        ayuradzan   \n",
       "2    2023-01-31  kereta cepat 2023-01-17 22:20:03+00:00         mase_aga   \n",
       "3    2023-01-31  kereta cepat 2023-01-17 20:23:14+00:00   Mustafic_Khzan   \n",
       "4    2023-01-31  kereta cepat 2023-01-17 20:16:39+00:00          dsyauls   \n",
       "..          ...           ...                       ...              ...   \n",
       "499  2023-01-31  kereta cepat 2023-01-13 01:37:36+00:00   handokosupraja   \n",
       "500  2023-01-31  kereta cepat 2023-01-13 01:35:11+00:00        mssyahira   \n",
       "501  2023-01-31  kereta cepat 2023-01-13 01:33:53+00:00        mssyahira   \n",
       "502  2023-01-31  kereta cepat 2023-01-13 00:27:01+00:00      abdul_karel   \n",
       "503  2023-01-31  kereta cepat 2023-01-13 00:20:27+00:00  giginpraginanto   \n",
       "\n",
       "                                                 tweet hashtags  \\\n",
       "0    @sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...     None   \n",
       "1    Early 18 dah dapat lesen kereta dah. kena cepa...     None   \n",
       "2    @Adabapaknya1 @sunuy_gans @worksfess Kalo kere...     None   \n",
       "3    Penerimaan pajak kita memang besar tapi Yang d...     None   \n",
       "4    @worksfess Harusnya kereta cepat itu Jakarta -...     None   \n",
       "..                                                 ...      ...   \n",
       "499  @endonesiatwit @Dennysiregar7 lu tua geblek pu...     None   \n",
       "500  Kereta boleh dapat cepat ni kalau Ativa Av, At...     None   \n",
       "501  Pesanan khidmat masyarakat untuk sesiapa yang ...     None   \n",
       "502  @Al4mSyahputra Krisis gara2  pinjam duit tdk p...     None   \n",
       "503  Para pengendali di pusat kekuasaan kelihatan s...     None   \n",
       "\n",
       "                                              mentions  likeCount  \\\n",
       "0    [https://twitter.com/sunuy_gans, https://twitt...          1   \n",
       "1                                                 None          0   \n",
       "2    [https://twitter.com/Adabapaknya1, https://twi...          1   \n",
       "3                                                 None          0   \n",
       "4                      [https://twitter.com/worksfess]          0   \n",
       "..                                                 ...        ...   \n",
       "499  [https://twitter.com/endonesiatwit, https://tw...          0   \n",
       "500                                               None          2   \n",
       "501                                               None         51   \n",
       "502                [https://twitter.com/Al4mSyahputra]          1   \n",
       "503                                               None        213   \n",
       "\n",
       "     retweetCount  replyCount  \n",
       "0               0           0  \n",
       "1               0           1  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               0           0  \n",
       "..            ...         ...  \n",
       "499             0           2  \n",
       "500             0           1  \n",
       "501            28           2  \n",
       "502             0           0  \n",
       "503           105          19  \n",
       "\n",
       "[504 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=3000): Max retries exceeded with url: /progress/twitter/id/2023-01-31%2012:36:57 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x142169ac0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x142169ac0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=3000): Max retries exceeded with url: /progress/twitter/id/2023-01-31%2012:36:57 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x142169ac0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/progress/twitter/id/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(APIurl,now))\u001b[39m.\u001b[39mjson()[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mid\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniforge3/envs/pySA/lib/python3.9/site-packages/requests/adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=3000): Max retries exceeded with url: /progress/twitter/id/2023-01-31%2012:36:57 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x142169ac0>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# id = requests.get('{}/progress/twitter/id/{}'.format(APIurl,now)).json()[0]['id']\n",
    "print(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(code):\n",
    "    requests.put('{}/progress/twitter/update'.format(APIurl), data={'id':id,'status': code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang Membersihkan Data Twitter...\n",
      "2023-01-24 00:08:59.071133\n",
      "cleaning text\n",
      "2023-01-24 00:08:59.074985\n",
      "casefolding text\n",
      "2023-01-24 00:08:59.078178\n",
      "tokenizing text\n",
      "2023-01-24 00:08:59.110523\n",
      "filtering text\n",
      "2023-01-24 00:08:59.176283\n",
      "stemming text\n",
      "Selesai Membersihkan Data Twitter :)\n",
      "2023-01-24 00:08:59.235065\n",
      "Sedang Menganalisis Sentimen Publik...\n",
      "2023-01-24 00:08:59.236910\n",
      "Selesai Menganalisis Sentimen Publik :)\n",
      "2023-01-24 00:08:59.382678\n",
      "timestamp             object\n",
      "keyword               object\n",
      "date                  object\n",
      "user                  object\n",
      "tweet                 object\n",
      "hashtags              object\n",
      "mentions              object\n",
      "likeCount              int64\n",
      "retweetCount           int64\n",
      "replyCount             int64\n",
      "text_clean            object\n",
      "text_preprocessed     object\n",
      "popularityScore      float64\n",
      "sentiment             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if df.empty:\n",
    "    update(404)\n",
    "    print(\"Tidak ada data atau query keliru!\")\n",
    "else:\n",
    "    df = df.drop_duplicates(subset=['tweet'])\n",
    "    dataset = df\n",
    "    update(2)\n",
    "    #print(dataset)\n",
    "    print(\"Sedang Membersihkan Data Twitter...\")\n",
    "    #gabungin hashtags\n",
    "    # dataset['Hashtags'] = '-'.join(dataset['Hashtags'])\n",
    "    print(datetime.now())\n",
    "    print('cleaning text')\n",
    "    dataset['text_clean'] = dataset['tweet'].apply(cleaningText)\n",
    "    print(datetime.now())\n",
    "    print('casefolding text')\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(casefoldingText)\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(normalize_alay)\n",
    "    \n",
    "    print(datetime.now())\n",
    "    print('tokenizing text')\n",
    "    dataset['text_preprocessed'] = dataset['text_clean'].apply(tokenizingText)\n",
    "    print(datetime.now())\n",
    "    print(\"filtering text\")\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(filteringText)\n",
    "    print(datetime.now())\n",
    "    print('stemming text')\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(stemmingText)\n",
    "    dataset[\"popularityScore\"] = (dataset[\"likeCount\"] + dataset[\"retweetCount\"] + dataset[\"replyCount\"])/3\n",
    "    print(\"Selesai Membersihkan Data Twitter :)\")\n",
    "    print(datetime.now())\n",
    "\n",
    "        ###################################\n",
    "        ###      SENTIMENT ANALYSIS     ###\n",
    "        ###################################\n",
    "\n",
    "    print(\"Sedang Menganalisis Sentimen Publik...\")\n",
    "    update(3)\n",
    "\n",
    "    print(datetime.now())\n",
    "    # Make text preprocessed (tokenized) to untokenized with toSentence Function\n",
    "    X = dataset['text_preprocessed'].apply(toSentence)\n",
    "    X = tfidf_vectorizer.transform(X.values)\n",
    "    \n",
    "    # e = X.toarray()\n",
    "    # #rumus mean\n",
    "    # n = 0\n",
    "    # mean = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())/5000\n",
    "    #     mean.append(a)\n",
    "\n",
    "    # #standar deviasi\n",
    "    # n = 0\n",
    "    # stdev = []\n",
    "    # for i in e:\n",
    "    #     s = np.std(i.tolist())\n",
    "    #     stdev.append(s)\n",
    "\n",
    "    # #max value\n",
    "    # n = 0\n",
    "    # maks = []\n",
    "    # for i in e:\n",
    "    #     a = max(i.tolist())\n",
    "    #     maks.append(a)\n",
    "\n",
    "    # #sum\n",
    "    # n = 0\n",
    "    # summ = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())\n",
    "    #     summ.append(a)\n",
    "\n",
    "    # #count feature\n",
    "    # n = 0\n",
    "    # count = []\n",
    "    # for i in e:\n",
    "    #     a = sum(map(lambda x : x != 0, i.tolist()))\n",
    "    #     count.append(a)\n",
    "\n",
    "    # extra_X = np.column_stack((e, np.array(mean), np.array(stdev), np.array(maks), np.array(summ), np.array(count)))\n",
    "\n",
    "    # from scipy import sparse\n",
    "    # extra_X = sparse.csr_matrix(extra_X)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    dataset['sentiment'] = y_pred\n",
    "\n",
    "    polarity_decode = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n",
    "    dataset['sentiment'] = dataset['sentiment'].map(polarity_decode)\n",
    "    print(\"Selesai Menganalisis Sentimen Publik :)\")\n",
    "\n",
    "    print(datetime.now())\n",
    "\n",
    "    dataset['date'] = pd.to_datetime(dataset['date']).dt.date\n",
    "    dataset['date']=dataset['date'].astype(str)\n",
    "        \n",
    "    print(dataset.dtypes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 481 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   timestamp          481 non-null    object \n",
      " 1   keyword            481 non-null    object \n",
      " 2   date               481 non-null    object \n",
      " 3   user               481 non-null    object \n",
      " 4   tweet              481 non-null    object \n",
      " 5   hashtags           51 non-null     object \n",
      " 6   mentions           285 non-null    object \n",
      " 7   likeCount          481 non-null    int64  \n",
      " 8   retweetCount       481 non-null    int64  \n",
      " 9   replyCount         481 non-null    int64  \n",
      " 10  text_clean         481 non-null    object \n",
      " 11  text_preprocessed  481 non-null    object \n",
      " 12  popularityScore    481 non-null    float64\n",
      " 13  sentiment          481 non-null    object \n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 56.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>popularityScore</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Baekamee</td>\n",
       "      <td>@sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/sunuy_gans, https://twitt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>ayuradzan</td>\n",
       "      <td>Early 18 dah dapat lesen kereta dah. kena cepa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>mase_aga</td>\n",
       "      <td>@Adabapaknya1 @sunuy_gans @worksfess Kalo kere...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Adabapaknya1, https://twi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Mustafic_Khzan</td>\n",
       "      <td>Penerimaan pajak kita memang besar tapi Yang d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>dsyauls</td>\n",
       "      <td>@worksfess Harusnya kereta cepat itu Jakarta -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/worksfess]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>handokosupraja</td>\n",
       "      <td>@endonesiatwit @Dennysiregar7 lu tua geblek pu...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/endonesiatwit, https://tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Kereta boleh dapat cepat ni kalau Ativa Av, At...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Pesanan khidmat masyarakat untuk sesiapa yang ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>abdul_karel</td>\n",
       "      <td>@Al4mSyahputra Krisis gara2  pinjam duit tdk p...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Al4mSyahputra]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>giginpraginanto</td>\n",
       "      <td>Para pengendali di pusat kekuasaan kelihatan s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>216</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>113.666667</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp       keyword        date             user  \\\n",
       "0    2023-01-24  kereta cepat  2023-01-17         Baekamee   \n",
       "1    2023-01-24  kereta cepat  2023-01-17        ayuradzan   \n",
       "2    2023-01-24  kereta cepat  2023-01-17         mase_aga   \n",
       "3    2023-01-24  kereta cepat  2023-01-17   Mustafic_Khzan   \n",
       "4    2023-01-24  kereta cepat  2023-01-17          dsyauls   \n",
       "..          ...           ...         ...              ...   \n",
       "501  2023-01-24  kereta cepat  2023-01-13   handokosupraja   \n",
       "502  2023-01-24  kereta cepat  2023-01-13        mssyahira   \n",
       "503  2023-01-24  kereta cepat  2023-01-13        mssyahira   \n",
       "504  2023-01-24  kereta cepat  2023-01-13      abdul_karel   \n",
       "505  2023-01-24  kereta cepat  2023-01-13  giginpraginanto   \n",
       "\n",
       "                                                 tweet hashtags  \\\n",
       "0    @sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...     None   \n",
       "1    Early 18 dah dapat lesen kereta dah. kena cepa...     None   \n",
       "2    @Adabapaknya1 @sunuy_gans @worksfess Kalo kere...     None   \n",
       "3    Penerimaan pajak kita memang besar tapi Yang d...     None   \n",
       "4    @worksfess Harusnya kereta cepat itu Jakarta -...     None   \n",
       "..                                                 ...      ...   \n",
       "501  @endonesiatwit @Dennysiregar7 lu tua geblek pu...     None   \n",
       "502  Kereta boleh dapat cepat ni kalau Ativa Av, At...     None   \n",
       "503  Pesanan khidmat masyarakat untuk sesiapa yang ...     None   \n",
       "504  @Al4mSyahputra Krisis gara2  pinjam duit tdk p...     None   \n",
       "505  Para pengendali di pusat kekuasaan kelihatan s...     None   \n",
       "\n",
       "                                              mentions  likeCount  \\\n",
       "0    [https://twitter.com/sunuy_gans, https://twitt...          1   \n",
       "1                                                 None          0   \n",
       "2    [https://twitter.com/Adabapaknya1, https://twi...          1   \n",
       "3                                                 None          0   \n",
       "4                      [https://twitter.com/worksfess]          0   \n",
       "..                                                 ...        ...   \n",
       "501  [https://twitter.com/endonesiatwit, https://tw...          0   \n",
       "502                                               None          2   \n",
       "503                                               None         51   \n",
       "504                [https://twitter.com/Al4mSyahputra]          1   \n",
       "505                                               None        216   \n",
       "\n",
       "     retweetCount  replyCount  popularityScore sentiment  \n",
       "0               0           0         0.333333  Positive  \n",
       "1               0           1         0.333333   Neutral  \n",
       "2               0           1         0.666667   Neutral  \n",
       "3               0           0         0.000000  Negative  \n",
       "4               0           0         0.000000   Neutral  \n",
       "..            ...         ...              ...       ...  \n",
       "501             0           2         0.666667   Neutral  \n",
       "502             0           1         1.000000   Neutral  \n",
       "503            28           2        27.000000   Neutral  \n",
       "504             0           0         0.333333   Neutral  \n",
       "505           106          19       113.666667  Positive  \n",
       "\n",
       "[481 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset[['timestamp', 'keyword', 'date', 'user', 'tweet', 'hashtags', 'mentions', 'likeCount', 'retweetCount', 'replyCount','popularityScore',  'sentiment']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>popularityScore</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Baekamee</td>\n",
       "      <td>@sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/sunuy_gans, https://twitt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>ayuradzan</td>\n",
       "      <td>Early 18 dah dapat lesen kereta dah. kena cepa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>mase_aga</td>\n",
       "      <td>@Adabapaknya1 @sunuy_gans @worksfess Kalo kere...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Adabapaknya1, https://twi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Mustafic_Khzan</td>\n",
       "      <td>Penerimaan pajak kita memang besar tapi Yang d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>dsyauls</td>\n",
       "      <td>@worksfess Harusnya kereta cepat itu Jakarta -...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/worksfess]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>handokosupraja</td>\n",
       "      <td>@endonesiatwit @Dennysiregar7 lu tua geblek pu...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/endonesiatwit, https://tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Kereta boleh dapat cepat ni kalau Ativa Av, At...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>mssyahira</td>\n",
       "      <td>Pesanan khidmat masyarakat untuk sesiapa yang ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>abdul_karel</td>\n",
       "      <td>@Al4mSyahputra Krisis gara2  pinjam duit tdk p...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/Al4mSyahputra]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>giginpraginanto</td>\n",
       "      <td>Para pengendali di pusat kekuasaan kelihatan s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>216</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>113.666667</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp       keyword        date             user  \\\n",
       "0    2023-01-24  kereta cepat  2023-01-17         Baekamee   \n",
       "1    2023-01-24  kereta cepat  2023-01-17        ayuradzan   \n",
       "2    2023-01-24  kereta cepat  2023-01-17         mase_aga   \n",
       "3    2023-01-24  kereta cepat  2023-01-17   Mustafic_Khzan   \n",
       "4    2023-01-24  kereta cepat  2023-01-17          dsyauls   \n",
       "..          ...           ...         ...              ...   \n",
       "501  2023-01-24  kereta cepat  2023-01-13   handokosupraja   \n",
       "502  2023-01-24  kereta cepat  2023-01-13        mssyahira   \n",
       "503  2023-01-24  kereta cepat  2023-01-13        mssyahira   \n",
       "504  2023-01-24  kereta cepat  2023-01-13      abdul_karel   \n",
       "505  2023-01-24  kereta cepat  2023-01-13  giginpraginanto   \n",
       "\n",
       "                                                 tweet hashtags  \\\n",
       "0    @sunuy_gans @Adabapaknya1 @worksfess Iyaa kare...     None   \n",
       "1    Early 18 dah dapat lesen kereta dah. kena cepa...     None   \n",
       "2    @Adabapaknya1 @sunuy_gans @worksfess Kalo kere...     None   \n",
       "3    Penerimaan pajak kita memang besar tapi Yang d...     None   \n",
       "4    @worksfess Harusnya kereta cepat itu Jakarta -...     None   \n",
       "..                                                 ...      ...   \n",
       "501  @endonesiatwit @Dennysiregar7 lu tua geblek pu...     None   \n",
       "502  Kereta boleh dapat cepat ni kalau Ativa Av, At...     None   \n",
       "503  Pesanan khidmat masyarakat untuk sesiapa yang ...     None   \n",
       "504  @Al4mSyahputra Krisis gara2  pinjam duit tdk p...     None   \n",
       "505  Para pengendali di pusat kekuasaan kelihatan s...     None   \n",
       "\n",
       "                                              mentions  likeCount  \\\n",
       "0    [https://twitter.com/sunuy_gans, https://twitt...          1   \n",
       "1                                                 None          0   \n",
       "2    [https://twitter.com/Adabapaknya1, https://twi...          1   \n",
       "3                                                 None          0   \n",
       "4                      [https://twitter.com/worksfess]          0   \n",
       "..                                                 ...        ...   \n",
       "501  [https://twitter.com/endonesiatwit, https://tw...          0   \n",
       "502                                               None          2   \n",
       "503                                               None         51   \n",
       "504                [https://twitter.com/Al4mSyahputra]          1   \n",
       "505                                               None        216   \n",
       "\n",
       "     retweetCount  replyCount  popularityScore sentiment  \n",
       "0               0           0         0.333333  Positive  \n",
       "1               0           1         0.333333   Neutral  \n",
       "2               0           1         0.666667   Neutral  \n",
       "3               0           0         0.000000  Negative  \n",
       "4               0           0         0.000000   Neutral  \n",
       "..            ...         ...              ...       ...  \n",
       "501             0           2         0.666667   Neutral  \n",
       "502             0           1         1.000000   Neutral  \n",
       "503            28           2        27.000000   Neutral  \n",
       "504             0           0         0.333333   Neutral  \n",
       "505           106          19       113.666667  Positive  \n",
       "\n",
       "[481 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['timestamp','date']] = df[['timestamp','date']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = df.to_json(\"./test_data/json.json\",orient='records')\n",
    "data_dict = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [500]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in data_dict:\n",
    "    dicts ={\n",
    "        'dateGet':i['timestamp'],\n",
    "        'keyword':i['keyword'],\n",
    "        'contentDate':i['date'],\n",
    "        'username':i['user'],\n",
    "        'tweet':i['tweet'],\n",
    "        'hashtags':i['hashtags'],\n",
    "        'mentions':i['mentions'],\n",
    "        'likeCount':i['likeCount'],\n",
    "        'retweetCount':i['retweetCount'],\n",
    "        'replyCount':i['replyCount'],\n",
    "        'popularityScore':i['popularityScore'],\n",
    "        'sentiment':i['sentiment'],\n",
    "        'topic':topic\n",
    "        }\n",
    "    # print(dicts)\n",
    "    c = requests.post('{}/data/twitter'.format(APIurl),dicts )\n",
    "    print(c)\n",
    "\n",
    "update(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanData[['Tweet', 'Result Prediction', 'text_preprocessed']].to_csv('pemilu.csv')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashtags = df[['keyword','date','hashtags','sentiment']]\n",
    "df_hashtags = df_hashtags[df_hashtags['hashtags'].notna()].reset_index()\n",
    "df_mentions = df[['keyword','date','mentions','sentiment']]\n",
    "df_mentions = df_mentions[df_mentions['mentions'].notna()].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mentions = df[['keyword','date','mentions','sentiment']]\n",
    "df_mentions = df_mentions[df_mentions['mentions'].notna()].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>[https://twitter.com/sunuy_gans, https://twitt...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>[https://twitter.com/Adabapaknya1, https://twi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>[https://twitter.com/worksfess]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>[https://twitter.com/kuasabu2, https://twitter...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>[https://twitter.com/worksfess]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>497</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>[https://twitter.com/novykayra, https://twitte...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>498</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>[https://twitter.com/txtdaribogor]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>500</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>[https://twitter.com/Paltiwest, https://twitte...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>501</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>[https://twitter.com/endonesiatwit, https://tw...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>504</td>\n",
       "      <td>kereta cepat</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>[https://twitter.com/Al4mSyahputra]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       keyword        date  \\\n",
       "0        0  kereta cepat  2023-01-17   \n",
       "1        2  kereta cepat  2023-01-17   \n",
       "2        4  kereta cepat  2023-01-17   \n",
       "3        8  kereta cepat  2023-01-17   \n",
       "4       12  kereta cepat  2023-01-17   \n",
       "..     ...           ...         ...   \n",
       "280    497  kereta cepat  2023-01-13   \n",
       "281    498  kereta cepat  2023-01-13   \n",
       "282    500  kereta cepat  2023-01-13   \n",
       "283    501  kereta cepat  2023-01-13   \n",
       "284    504  kereta cepat  2023-01-13   \n",
       "\n",
       "                                              mentions sentiment  \n",
       "0    [https://twitter.com/sunuy_gans, https://twitt...  Positive  \n",
       "1    [https://twitter.com/Adabapaknya1, https://twi...   Neutral  \n",
       "2                      [https://twitter.com/worksfess]   Neutral  \n",
       "3    [https://twitter.com/kuasabu2, https://twitter...   Neutral  \n",
       "4                      [https://twitter.com/worksfess]   Neutral  \n",
       "..                                                 ...       ...  \n",
       "280  [https://twitter.com/novykayra, https://twitte...   Neutral  \n",
       "281                 [https://twitter.com/txtdaribogor]   Neutral  \n",
       "282  [https://twitter.com/Paltiwest, https://twitte...   Neutral  \n",
       "283  [https://twitter.com/endonesiatwit, https://tw...   Neutral  \n",
       "284                [https://twitter.com/Al4mSyahputra]   Neutral  \n",
       "\n",
       "[285 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_hashtags.shape[0]):\n",
    "    for j in range(len(df_hashtags['hashtags'][i])):\n",
    "        contentDate = df_hashtags['date'][i]\n",
    "        keyword = df_hashtags['keyword'][i]\n",
    "        hashtag = df_hashtags['hashtags'][i][j]\n",
    "        sentiment = df_hashtags['sentiment'][i]\n",
    "        if hashtag != 0:\n",
    "            requests.post('{}/data/twitter/content'.format(APIurl),{\n",
    "                'contentDate' : contentDate,\n",
    "                'topic' : topic,\n",
    "                'keyword' : keyword,\n",
    "                'content' : hashtag,\n",
    "                'type' : 'hashtag',\n",
    "                'sentiment' : sentiment\n",
    "            } )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@sunuy_gans\n",
      "@Adabapaknya1\n",
      "@worksfess\n",
      "@Adabapaknya1\n",
      "@sunuy_gans\n",
      "@worksfess\n",
      "@worksfess\n",
      "@kuasabu2\n",
      "@riecho_reeboun\n",
      "@Dennysiregar7\n",
      "@worksfess\n",
      "@kelapakopyorr\n",
      "@KAI121\n",
      "@AirinDatangLagi\n",
      "@worksfess\n",
      "@HwrNfl\n",
      "@marwanFC\n",
      "@worksfess\n",
      "@CommuterLine\n",
      "@Yorkeous\n",
      "@hannajoe20\n",
      "@karniilyas\n",
      "@kaesangp\n",
      "@kaesangp\n",
      "@ridwankamil\n",
      "@worksfess\n",
      "@ridwankamil\n",
      "@democrazymedia\n",
      "@sadlybey\n",
      "@daevus_\n",
      "@marwanFC\n",
      "@worksfess\n",
      "@CommuterLine\n",
      "@jalur5_\n",
      "@worksfess\n",
      "@kemenkomarves\n",
      "@upikxc\n",
      "@LuqmanBeeNKRI\n",
      "@lilcigart\n",
      "@sunuy_gans\n",
      "@worksfess\n",
      "@RuangLucuuu\n",
      "@HelmiFelis_\n",
      "@RuangLucuuu\n",
      "@worksfess\n",
      "@dwambrrr\n",
      "@sunuy_gans\n",
      "@worksfess\n",
      "@worksfess\n",
      "@RuangLucuuu\n",
      "@urcottoncandyy\n",
      "@worksfess\n",
      "@tanyakanrl\n",
      "@BuletinTV3\n",
      "@worksfess\n",
      "@andreasstrp\n",
      "@marwanFC\n",
      "@worksfess\n",
      "@CommuterLine\n",
      "@worksfess\n",
      "@2TitikHitam\n",
      "@hannajoe20\n",
      "@karniilyas\n",
      "@sunuy_gans\n",
      "@worksfess\n",
      "@worksfess\n",
      "@fauzan69899430\n",
      "@Dediy_orlando\n",
      "@Dennysiregar7\n",
      "@ganjarpranowo\n",
      "@jokowi\n",
      "@ridwankamil\n",
      "@antoanto_\n",
      "@dododid64453759\n",
      "@BradHarizz\n",
      "@worksfess\n",
      "@KAI121\n",
      "@KemenBUMN\n",
      "@fauzan69899430\n",
      "@Dediy_orlando\n",
      "@Dennysiregar7\n",
      "@ganjarpranowo\n",
      "@jokowi\n",
      "@ridwankamil\n",
      "@Vanadis88624895\n",
      "@SantorinisSun\n",
      "@nusantara_one\n",
      "@KPK_RI\n",
      "@KejaksaanRI\n",
      "@DivHumas_Polri\n",
      "@CCICPolri\n",
      "@mohmahfudmd\n",
      "@Dennysiregar7\n",
      "@NasDem\n",
      "@jokowi\n",
      "@Rhoemeoadhamz\n",
      "@blank0429\n",
      "@worksfess\n",
      "@worksfess\n",
      "@BobLaser10\n",
      "@RamliRizal\n",
      "@RamliRizal\n",
      "@GheaJhanaLie7\n",
      "@Bool_81\n",
      "@Irwan2yah1\n",
      "@CommuterLine\n",
      "@zarnaout45\n",
      "@OposisiCerdas\n",
      "@TeguhTimurCom\n",
      "@petruspasaribuu\n",
      "@jokowi\n",
      "@blessthefaII_\n",
      "@w_i_d_h_i\n",
      "@pengarang_sajak\n",
      "@Jusup_Rianto\n",
      "@kompascom\n",
      "@AqiaqiH\n",
      "@AirinDatangLagi\n",
      "@SBYudhoyono\n",
      "@RKevin_Ramdhani\n",
      "@JulBayur3\n",
      "@endonesiatwit\n",
      "@KINGsm4kers\n",
      "@karniilyas\n",
      "@AqiaqiH\n",
      "@JoharBaru2024\n",
      "@kartarahardja\n",
      "@ZMannaroy\n",
      "@Outstandjing\n",
      "@OposisiCerdas\n",
      "@detikcom\n",
      "@Pencerah___\n",
      "@Dublin2Eric\n",
      "@PEncarah\n",
      "@Krackovwia\n",
      "@sumadiharis\n",
      "@Dennysiregar7\n",
      "@Askrlfess\n",
      "@agung_dk\n",
      "@indra_mbb\n",
      "@AqiaqiH\n",
      "@jokowi\n",
      "@Askrlfess\n",
      "@Askrlfess\n",
      "@CNN\n",
      "@Askrlfess\n",
      "@MakarunaNow\n",
      "@miskinilmu\n",
      "@maspiyu_aja\n",
      "@Outstandjing\n",
      "@bajulcilik\n",
      "@nusantara_one\n",
      "@mairaeeer\n",
      "@blank0429\n",
      "@Outstandjing\n",
      "@cenie_girl\n",
      "@cenie_girl\n",
      "@Kanseulir__\n",
      "@bang_dua\n",
      "@Kopipait__78\n",
      "@MudasirRomini\n",
      "@Dennysiregar7\n",
      "@MardaniAliSera\n",
      "@ridwankamil\n",
      "@jokowi\n",
      "@wewegomb\n",
      "@Karsono12732862\n",
      "@HisyamMochtar\n",
      "@pantograp\n",
      "@sahabat_kereta\n",
      "@MenHub1\n",
      "@BudiKaryaS\n",
      "@KeretaCepatID\n",
      "@kejususu00\n",
      "@Jamaludinsoleh\n",
      "@_NazriH\n",
      "@ismailfahmi\n",
      "@susiair\n",
      "@SimanjuntakElly\n",
      "@Raka_7804\n",
      "@BkBahrul\n",
      "@RelawanNusanta1\n",
      "@JKRSelangor\n",
      "@psi_id\n",
      "@ismailfahmi\n",
      "@susiair\n",
      "@OposisiCerdas\n",
      "@shimee_ya\n",
      "@RKevin_Ramdhani\n",
      "@tokidokicircle\n",
      "@SemutMerah2024\n",
      "@suara1hati\n",
      "@shimee_ya\n",
      "@kartarahardja\n",
      "@BecengAparat\n",
      "@kurawa\n",
      "@jijieazrin\n",
      "@farhan_fevrier\n",
      "@ngabdul\n",
      "@myPKPS\n",
      "@AnkerTwiter\n",
      "@kartarahardja\n",
      "@ZMannaroy\n",
      "@muannas_alaidid\n",
      "@MudasirRomini\n",
      "@Dennysiregar7\n",
      "@MardaniAliSera\n",
      "@ridwankamil\n",
      "@BangEdiii\n",
      "@Kedai_Fakarezo\n",
      "@jawapos\n",
      "@yuwyutik\n",
      "@LittleJ98595985\n",
      "@DokterTifa\n",
      "@DokterTifa\n",
      "@KAI121\n",
      "@cindy_pon\n",
      "@arbellesov\n",
      "@faridgaban\n",
      "@convomf\n",
      "@OposisiCerdas\n",
      "@beetrying\n",
      "@nalar_logis\n",
      "@tatakujiyati\n",
      "@msaid_didu\n",
      "@jokowi\n",
      "@ssefnum\n",
      "@olahantempe\n",
      "@f_gilik\n",
      "@txtdrjkt\n",
      "@CNNIndonesia\n",
      "@aerisugarr\n",
      "@gururidho\n",
      "@RMSigalingging1\n",
      "@aniesbaswedan\n",
      "@cityoflondon\n",
      "@baliandra2\n",
      "@Dennysiregar7\n",
      "@NasDem\n",
      "@Dennysiregar7\n",
      "@NasDem\n",
      "@RXsuci\n",
      "@mynameisowi\n",
      "@Dennysiregar7\n",
      "@NasDem\n",
      "@DokterTifa\n",
      "@Miduk17\n",
      "@ngabdul\n",
      "@BangEdiii\n",
      "@tanyakanrl\n",
      "@ngabdul\n",
      "@kartarahardja\n",
      "@BecengAparat\n",
      "@detikcom\n",
      "@RajaJuliAntoni\n",
      "@temponewsroom\n",
      "@kompascom\n",
      "@detikcom\n",
      "@TirtoID\n",
      "@AimanWitjaksono\n",
      "@KompasTV\n",
      "@tvOneNews\n",
      "@Metro_TV\n",
      "@MaiAbdi1\n",
      "@Miduk17\n",
      "@baliandra2\n",
      "@NagaVVijaya\n",
      "@Dennysiregar7\n",
      "@NasDem\n",
      "@wawanfa17\n",
      "@cR17imo\n",
      "@idextratime\n",
      "@DokterTifa\n",
      "@santri_keliling\n",
      "@SiaranBolaLive\n",
      "@RadenmasNugroho\n",
      "@AbdulKh29602993\n",
      "@Tita83079013\n",
      "@ridwankamil\n",
      "@RoninBasis\n",
      "@Mukidi_alNgibul\n",
      "@jinjelek\n",
      "@baliandra2\n",
      "@BangEdiii\n",
      "@BangEdiii\n",
      "@psi_id\n",
      "@Bernardo_susant\n",
      "@anggahandika20\n",
      "@SiaranBolaLive\n",
      "@TofikHi85890660\n",
      "@aniesbaswedan\n",
      "@cityoflondon\n",
      "@acaiijawe\n",
      "@detikcom\n",
      "@DokterTifa\n",
      "@psi_id\n",
      "@chefbane1\n",
      "@Gherucokro1\n",
      "@BangEdiii\n",
      "@Tita83079013\n",
      "@ch_chotimah2\n",
      "@Pradaprasetya21\n",
      "@TeddGus\n",
      "@SBYudhoyono\n",
      "@ikramwiese\n",
      "@Tita83079013\n",
      "@ridwankamil\n",
      "@gumpnhell\n",
      "@JSuryoP1\n",
      "@_TNIAU\n",
      "@diongideon\n",
      "@AdeDani03\n",
      "@ZeboLady\n",
      "@pooyoyo\n",
      "@_bobobaebae\n",
      "@convomfs\n",
      "@Bernardo_susant\n",
      "@SiaranBolaLive\n",
      "@Azhar_k18\n",
      "@kabarpenumpang\n",
      "@BangEdiii\n",
      "@Paltiwest\n",
      "@bagus_carito\n",
      "@fedriza\n",
      "@SiaranBolaLive\n",
      "@asrori_kudus\n",
      "@Paltiwest\n",
      "@psi_id\n",
      "@SiaranBolaLive\n",
      "@tanyakanrl\n",
      "@jllmisai\n",
      "@Abdillahonim\n",
      "@Askrlfess\n",
      "@BangEdiii\n",
      "@CeritaCintaFess\n",
      "@SiaranBolaLive\n",
      "@BangEdiii\n",
      "@Midjan_La_2\n",
      "@wahju_wibowo\n",
      "@SiaranBolaLive\n",
      "@SiaranBolaLive\n",
      "@BangEdiii\n",
      "@YooStoleMaHeart\n",
      "@SiaranBolaLive\n",
      "@eveantoinette_\n",
      "@KabarGolkarCom\n",
      "@ismailfahmi\n",
      "@susiair\n",
      "@BangEdiii\n",
      "@susipudjiastuti\n",
      "@DPR_RI\n",
      "@NamungAbdiGusti\n",
      "@kelapamuddah\n",
      "@Nagashima007\n",
      "@baliandra2\n",
      "@Bunga_Maw4R6027\n",
      "@Nagashima007\n",
      "@baliandra2\n",
      "@Bunga_Maw4R6027\n",
      "@Twt_Cyberjaya\n",
      "@psi_id\n",
      "@baliandra2\n",
      "@Paltiwest\n",
      "@ikn_id\n",
      "@kurawa\n",
      "@PSI_Jakarta\n",
      "@xnakw2\n",
      "@rezhend\n",
      "@VIVAcoid\n",
      "@baliandra2\n",
      "@rasjawa\n",
      "@rizkidwika\n",
      "@ZeboLady\n",
      "@WinnerWave_\n",
      "@baliandra2\n",
      "@naiys__\n",
      "@RAP1612RAP\n",
      "@susipudjiastuti\n",
      "@Wahyu9\n",
      "@cisirol\n",
      "@raegspatter\n",
      "@baliandra2\n",
      "@JaenoXTM\n",
      "@BangDa079\n",
      "@henrisabastian1\n",
      "@baliandra2\n",
      "@_MbakSri_\n",
      "@kurawa\n",
      "@RoyalFaiiry\n",
      "@Strategi_Bisnis\n",
      "@PriatnaGaluh\n",
      "@KokoGiovanni\n",
      "@KAI121\n",
      "@Pencerah___\n",
      "@Relawananies\n",
      "@PrayogiYulistio\n",
      "@FerryFurqond\n",
      "@VIVAcoid\n",
      "@UniofOxford\n",
      "@hubdat151\n",
      "@convomf\n",
      "@indowfofficial\n",
      "@KPK_RI\n",
      "@Toklexloveunyil\n",
      "@panca66\n",
      "@Askrlfess\n",
      "@Miduk17\n",
      "@SiaranBolaLive\n",
      "@w1nker\n",
      "@TarunaAdjie1\n",
      "@kurawa\n",
      "@BungDenni\n",
      "@yusuf_dumdum\n",
      "@detikcom\n",
      "@tatakujiyati\n",
      "@yusuf_dumdum\n",
      "@detikcom\n",
      "@tatakujiyati\n",
      "@starfess\n",
      "@aqua_gak\n",
      "@ArdjunaWiwaha3l\n",
      "@23wbmy\n",
      "@OposisiCerdas\n",
      "@OposisiCerdas\n",
      "@KokoGiovanni\n",
      "@KAI121\n",
      "@Askrlfess\n",
      "@tanyakanrl\n",
      "@txtdrimedia\n",
      "@OposisiCerdas\n",
      "@BakomstraPD\n",
      "@MIrvanDarwin1\n",
      "@BakomstraPD\n",
      "@ryorossi4689\n",
      "@BakomstraPD\n",
      "@PonorogoSupra\n",
      "@Hasbil_Lbs\n",
      "@wortelsoup\n",
      "@bigwinjanuarii\n",
      "@tanyakanrl\n",
      "@rgantas\n",
      "@ArdjunaWiwaha3l\n",
      "@kurawa\n",
      "@kaypdf\n",
      "@kurawa\n",
      "@kurawa\n",
      "@kurawa\n",
      "@kurawa\n",
      "@AnthonyBudiawan\n",
      "@SahabatSaber\n",
      "@kirim_aja\n",
      "@maspiyu_aja\n",
      "@Fahrihamzah\n",
      "@novykayra\n",
      "@BBCIndonesia\n",
      "@PresidenKopi\n",
      "@jokowi\n",
      "@tisudankapas\n",
      "@Miduk17\n",
      "@suryadijepe\n",
      "@tanyakanrl\n",
      "@yosi_hs\n",
      "@yusuf_dumdum\n",
      "@novykayra\n",
      "@BBCIndonesia\n",
      "@txtdaribogor\n",
      "@Paltiwest\n",
      "@ikn_id\n",
      "@endonesiatwit\n",
      "@Dennysiregar7\n",
      "@Al4mSyahputra\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_mentions.shape[0]):\n",
    "    for j in range(len(df_mentions['mentions'][i])):\n",
    "        contentDate = df_mentions['date'][i]\n",
    "        keyword = df_mentions['keyword'][i]\n",
    "        mention = str(df_mentions['mentions'][i][j]).replace('https://twitter.com/', '@')\n",
    "        sentiment = df_mentions['sentiment'][i]\n",
    "        if mention != 0:\n",
    "            requests.post('{}/data/twitter/content'.format(APIurl),{\n",
    "                'contentDate' : contentDate,\n",
    "                'topic' : topic,\n",
    "                'keyword' : keyword,\n",
    "                'content' : mention,\n",
    "                'type' : 'mention',\n",
    "                'sentiment' : sentiment\n",
    "            } )\n",
    "            print(mention)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SELECT  content,\n",
    "# \tCOUNT( IF( sentiment = 'Positive',1,  NULL) ) AS 'positive',\n",
    "# \tCOUNT( IF( sentiment = 'Neutral',1, NULL) ) AS 'neutral',\n",
    "# \tCOUNT( IF( sentiment = 'Negative',1, Null) ) AS 'negative',\n",
    "# \tCOUNT(sentiment) AS 'total'\n",
    "# FROM twitter_content\n",
    "# WHERE type = 'mention'\n",
    "# GROUP BY content\n",
    "# ORDER BY total desc;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "872e9ac453f67b7e35588ebe4d602923bc34b4c5daddde36c325676c5fe52d29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
