{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_7975/3466385359.py:1: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator SVC from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_7975/3466385359.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/qoisoctava/miniforge3/envs/pySA/lib/python3.9/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('./old/modelSVC.pickle','rb'))\n",
    "tfidf_vectorizer =  pickle.load(open('./old/tfidf_vectorizer.pickle','rb'))\n",
    "APIurl = 'http://127.0.0.1:3000'\n",
    "req = requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraperKey(keyword,date_since,date_until):\n",
    "    query = keyword+\" lang:id until:\"+str(date_until)+\" since:\"+str(date_since)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    req.post('{}/progress/new'.format(APIurl),{'dateGet':now,'keyword':keyword,'dateSince':date_since,'dateUntil':date_until,'status':1,'source':'tw'} )\n",
    "    #print(query)\n",
    "    #print(datetime.now())\n",
    "    #print(\"Sedang Mengumpulkan Data Twitter...\")\n",
    "    tweets = []\n",
    "    while len(tweets) <= 20:\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            tweets.append([datetime.now().date(), keyword, tweet.date, tweet.user.username, tweet.content, tweet.hashtags,tweet.mentionedUsers, tweet.likeCount, tweet.retweetCount, tweet.replyCount])\n",
    "        \n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(tweets, columns=['timestamp','keyword','date', 'user', 'tweet', 'hashtags', 'mentions', 'likeCount', 'retweetCount', 'replyCount'])\n",
    "    return df,now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode() #remove emojis\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
    "    text = word_tokenize(text) \n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Remove stopwors in a text\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    text = [w for w in text if not w in listStopwords]\n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    #factory = StemmerFactory()\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n",
    "\n",
    "alay_dict = pd.read_csv('colloquial-indonesian-lexicon.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', 1: 'replacement'})\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "\n",
    "def normalize_alay(text):\n",
    " text = ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    " text = re.sub(' +', ' ', text)\n",
    " return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/fxrhbppn0ds9grnhwp1j2qfm0000gn/T/ipykernel_7975/1687530207.py:11: FutureWarning: content is deprecated, use rawContent instead\n",
      "  tweets.append([datetime.now().date(), keyword, tweet.date, tweet.user.username, tweet.content, tweet.hashtags,tweet.mentionedUsers, tweet.likeCount, tweet.retweetCount, tweet.replyCount])\n"
     ]
    }
   ],
   "source": [
    "df, now = scraperKey('bandara yia','2023-01-13','2023-01-14')\n",
    "topic = 'wisata jogja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "id = requests.get('{}/progress/id/{}'.format(APIurl,now)).json()[0]['id']\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(code):\n",
    "    req.put('{}/progress/update'.format(APIurl), data={'id':id,'status': code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang Membersihkan Data Twitter...\n",
      "2023-01-14 17:26:04.600191\n",
      "cleaning text\n",
      "2023-01-14 17:26:04.600776\n",
      "casefolding text\n",
      "2023-01-14 17:26:04.601143\n",
      "tokenizing text\n",
      "2023-01-14 17:26:04.602080\n",
      "filtering text\n",
      "2023-01-14 17:26:04.604520\n",
      "stemming text\n",
      "Selesai Membersihkan Data Twitter :)\n",
      "2023-01-14 17:26:04.606298\n",
      "Sedang Menganalisis Sentimen Publik...\n",
      "2023-01-14 17:26:04.608559\n",
      "Selesai Menganalisis Sentimen Publik :)\n",
      "2023-01-14 17:26:04.614020\n",
      "timestamp             object\n",
      "keyword               object\n",
      "date                  object\n",
      "user                  object\n",
      "tweet                 object\n",
      "hashtags              object\n",
      "mentions              object\n",
      "likeCount              int64\n",
      "retweetCount           int64\n",
      "replyCount             int64\n",
      "text_clean            object\n",
      "text_preprocessed     object\n",
      "popularityScore      float64\n",
      "sentiment             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if df.empty:\n",
    "    update(404)\n",
    "    print(\"Tidak ada data atau query keliru!\")\n",
    "else:\n",
    "    df = df.drop_duplicates(subset=['tweet'])\n",
    "    dataset = df\n",
    "    update(2)\n",
    "    #print(dataset)\n",
    "    print(\"Sedang Membersihkan Data Twitter...\")\n",
    "    #gabungin hashtags\n",
    "    # dataset['Hashtags'] = '-'.join(dataset['Hashtags'])\n",
    "    print(datetime.now())\n",
    "    print('cleaning text')\n",
    "    dataset['text_clean'] = dataset['tweet'].apply(cleaningText)\n",
    "    print(datetime.now())\n",
    "    print('casefolding text')\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(casefoldingText)\n",
    "    dataset['text_clean'] = dataset['text_clean'].apply(normalize_alay)\n",
    "    \n",
    "    print(datetime.now())\n",
    "    print('tokenizing text')\n",
    "    dataset['text_preprocessed'] = dataset['text_clean'].apply(tokenizingText)\n",
    "    print(datetime.now())\n",
    "    print(\"filtering text\")\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(filteringText)\n",
    "    print(datetime.now())\n",
    "    print('stemming text')\n",
    "    dataset['text_preprocessed'] = dataset['text_preprocessed'].apply(stemmingText)\n",
    "    dataset[\"popularityScore\"] = (dataset[\"likeCount\"] + dataset[\"retweetCount\"] + dataset[\"replyCount\"])/3\n",
    "    print(\"Selesai Membersihkan Data Twitter :)\")\n",
    "    print(datetime.now())\n",
    "\n",
    "        ###################################\n",
    "        ###      SENTIMENT ANALYSIS     ###\n",
    "        ###################################\n",
    "\n",
    "    print(\"Sedang Menganalisis Sentimen Publik...\")\n",
    "    update(3)\n",
    "\n",
    "    print(datetime.now())\n",
    "    # Make text preprocessed (tokenized) to untokenized with toSentence Function\n",
    "    X = dataset['text_preprocessed'].apply(toSentence)\n",
    "    X = tfidf_vectorizer.transform(X.values)\n",
    "    \n",
    "    # e = X.toarray()\n",
    "    # #rumus mean\n",
    "    # n = 0\n",
    "    # mean = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())/5000\n",
    "    #     mean.append(a)\n",
    "\n",
    "    # #standar deviasi\n",
    "    # n = 0\n",
    "    # stdev = []\n",
    "    # for i in e:\n",
    "    #     s = np.std(i.tolist())\n",
    "    #     stdev.append(s)\n",
    "\n",
    "    # #max value\n",
    "    # n = 0\n",
    "    # maks = []\n",
    "    # for i in e:\n",
    "    #     a = max(i.tolist())\n",
    "    #     maks.append(a)\n",
    "\n",
    "    # #sum\n",
    "    # n = 0\n",
    "    # summ = []\n",
    "    # for i in e:\n",
    "    #     a = sum(i.tolist())\n",
    "    #     summ.append(a)\n",
    "\n",
    "    # #count feature\n",
    "    # n = 0\n",
    "    # count = []\n",
    "    # for i in e:\n",
    "    #     a = sum(map(lambda x : x != 0, i.tolist()))\n",
    "    #     count.append(a)\n",
    "\n",
    "    # extra_X = np.column_stack((e, np.array(mean), np.array(stdev), np.array(maks), np.array(summ), np.array(count)))\n",
    "\n",
    "    # from scipy import sparse\n",
    "    # extra_X = sparse.csr_matrix(extra_X)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    dataset['sentiment'] = y_pred\n",
    "\n",
    "    polarity_decode = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n",
    "    dataset['sentiment'] = dataset['sentiment'].map(polarity_decode)\n",
    "    print(\"Selesai Menganalisis Sentimen Publik :)\")\n",
    "\n",
    "    print(datetime.now())\n",
    "\n",
    "    dataset['date'] = pd.to_datetime(dataset['date']).dt.date\n",
    "    dataset['date']=dataset['date'].astype(str)\n",
    "        \n",
    "    print(dataset.dtypes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11 entries, 0 to 10\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   timestamp          11 non-null     object \n",
      " 1   keyword            11 non-null     object \n",
      " 2   date               11 non-null     object \n",
      " 3   user               11 non-null     object \n",
      " 4   tweet              11 non-null     object \n",
      " 5   hashtags           3 non-null      object \n",
      " 6   mentions           3 non-null      object \n",
      " 7   likeCount          11 non-null     int64  \n",
      " 8   retweetCount       11 non-null     int64  \n",
      " 9   replyCount         11 non-null     int64  \n",
      " 10  text_clean         11 non-null     object \n",
      " 11  text_preprocessed  11 non-null     object \n",
      " 12  popularityScore    11 non-null     float64\n",
      " 13  sentiment          11 non-null     object \n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>popularityScore</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>midfieldeer14</td>\n",
       "      <td>Ada yang mau kerja di bandara lur khusus cewek...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>infobmkgyia</td>\n",
       "      <td>Hai #sobatbmkgyia,\\nBerikut kami sampaikan Pra...</td>\n",
       "      <td>[sobatbmkgyia, infobmkg, infobmkgyia, prakiraa...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>yosanaa_</td>\n",
       "      <td>Kenapa bandara yia jauh banget jadinya harus b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>Minariiiing</td>\n",
       "      <td>Bandara. \\nYIA Kulon Progo mantep sih. Viewnya...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>sewamobilmurah9</td>\n",
       "      <td>Ready city car matic manual\\nBiar bisa sat set...</td>\n",
       "      <td>[rentalmobiljogja, sewamobiljogja, rentalmobil...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>annipusphyta</td>\n",
       "      <td>Parkir mahal di Diy jatuh pada parkir vip band...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>stefanaezer</td>\n",
       "      <td>@KompasTV Dari bukan Jakarta Jogja, tp Tangera...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/KompasTV]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>CecanUtami</td>\n",
       "      <td>berapa harga tiket kereta bandara yia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>KAI121</td>\n",
       "      <td>@zeuschlad Selamat pagi Kak. Perjalanan KA Ban...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/zeuschlad, https://twitte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>jhnhpt</td>\n",
       "      <td>@UGM_FESS dari Jakarta ke Bandara juga perlu k...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/UGM_FESS]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>infobmkgyia</td>\n",
       "      <td>Halo #sobatbmkgyia...\\nBerikut Kami Sampaikan ...</td>\n",
       "      <td>[sobatbmkgyia, infobmkg, infobmkgyia, laporanc...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp      keyword        date             user  \\\n",
       "0   2023-01-14  bandara yia  2023-01-13    midfieldeer14   \n",
       "1   2023-01-14  bandara yia  2023-01-13      infobmkgyia   \n",
       "2   2023-01-14  bandara yia  2023-01-13         yosanaa_   \n",
       "3   2023-01-14  bandara yia  2023-01-13      Minariiiing   \n",
       "4   2023-01-14  bandara yia  2023-01-13  sewamobilmurah9   \n",
       "5   2023-01-14  bandara yia  2023-01-13     annipusphyta   \n",
       "6   2023-01-14  bandara yia  2023-01-13      stefanaezer   \n",
       "7   2023-01-14  bandara yia  2023-01-13       CecanUtami   \n",
       "8   2023-01-14  bandara yia  2023-01-13           KAI121   \n",
       "9   2023-01-14  bandara yia  2023-01-13           jhnhpt   \n",
       "10  2023-01-14  bandara yia  2023-01-13      infobmkgyia   \n",
       "\n",
       "                                                tweet  \\\n",
       "0   Ada yang mau kerja di bandara lur khusus cewek...   \n",
       "1   Hai #sobatbmkgyia,\\nBerikut kami sampaikan Pra...   \n",
       "2   Kenapa bandara yia jauh banget jadinya harus b...   \n",
       "3   Bandara. \\nYIA Kulon Progo mantep sih. Viewnya...   \n",
       "4   Ready city car matic manual\\nBiar bisa sat set...   \n",
       "5   Parkir mahal di Diy jatuh pada parkir vip band...   \n",
       "6   @KompasTV Dari bukan Jakarta Jogja, tp Tangera...   \n",
       "7               berapa harga tiket kereta bandara yia   \n",
       "8   @zeuschlad Selamat pagi Kak. Perjalanan KA Ban...   \n",
       "9   @UGM_FESS dari Jakarta ke Bandara juga perlu k...   \n",
       "10  Halo #sobatbmkgyia...\\nBerikut Kami Sampaikan ...   \n",
       "\n",
       "                                             hashtags  \\\n",
       "0                                                None   \n",
       "1   [sobatbmkgyia, infobmkg, infobmkgyia, prakiraa...   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4   [rentalmobiljogja, sewamobiljogja, rentalmobil...   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10  [sobatbmkgyia, infobmkg, infobmkgyia, laporanc...   \n",
       "\n",
       "                                             mentions  likeCount  \\\n",
       "0                                                None          8   \n",
       "1                                                None          1   \n",
       "2                                                None          0   \n",
       "3                                                None          0   \n",
       "4                                                None          0   \n",
       "5                                                None          0   \n",
       "6                      [https://twitter.com/KompasTV]          0   \n",
       "7                                                None          0   \n",
       "8   [https://twitter.com/zeuschlad, https://twitte...          0   \n",
       "9                      [https://twitter.com/UGM_FESS]          0   \n",
       "10                                               None          0   \n",
       "\n",
       "    retweetCount  replyCount  popularityScore sentiment  \n",
       "0              5           8         7.000000  Positive  \n",
       "1              0           0         0.333333  Positive  \n",
       "2              0           0         0.000000   Neutral  \n",
       "3              0           0         0.000000  Positive  \n",
       "4              0           0         0.000000  Positive  \n",
       "5              0           0         0.000000  Positive  \n",
       "6              0           0         0.000000   Neutral  \n",
       "7              0           0         0.000000   Neutral  \n",
       "8              0           1         0.333333  Positive  \n",
       "9              0           0         0.000000   Neutral  \n",
       "10             0           0         0.000000   Neutral  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset[['timestamp', 'keyword', 'date', 'user', 'tweet', 'hashtags', 'mentions', 'likeCount', 'retweetCount', 'replyCount','popularityScore',  'sentiment']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['Date','User','Tweet','Hashtags','Like','Retweet','Reply','Popularity Score','Result Prediction','keyword','timestamp']\n",
    "# df = cleanData[cols]\n",
    "# ncols = ['date','user','tweet','hashtags','like','retweet','reply','popularityScore','sentiment','keyword','timestamp']\n",
    "# send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>popularityScore</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>midfieldeer14</td>\n",
       "      <td>Ada yang mau kerja di bandara lur khusus cewek...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>infobmkgyia</td>\n",
       "      <td>Hai #sobatbmkgyia,\\nBerikut kami sampaikan Pra...</td>\n",
       "      <td>[sobatbmkgyia, infobmkg, infobmkgyia, prakiraa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>yosanaa_</td>\n",
       "      <td>Kenapa bandara yia jauh banget jadinya harus b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>Minariiiing</td>\n",
       "      <td>Bandara. \\nYIA Kulon Progo mantep sih. Viewnya...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>sewamobilmurah9</td>\n",
       "      <td>Ready city car matic manual\\nBiar bisa sat set...</td>\n",
       "      <td>[rentalmobiljogja, sewamobiljogja, rentalmobil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>annipusphyta</td>\n",
       "      <td>Parkir mahal di Diy jatuh pada parkir vip band...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>stefanaezer</td>\n",
       "      <td>@KompasTV Dari bukan Jakarta Jogja, tp Tangera...</td>\n",
       "      <td>0</td>\n",
       "      <td>[https://twitter.com/KompasTV]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>CecanUtami</td>\n",
       "      <td>berapa harga tiket kereta bandara yia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>KAI121</td>\n",
       "      <td>@zeuschlad Selamat pagi Kak. Perjalanan KA Ban...</td>\n",
       "      <td>0</td>\n",
       "      <td>[https://twitter.com/zeuschlad, https://twitte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>jhnhpt</td>\n",
       "      <td>@UGM_FESS dari Jakarta ke Bandara juga perlu k...</td>\n",
       "      <td>0</td>\n",
       "      <td>[https://twitter.com/UGM_FESS]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>bandara yia</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>infobmkgyia</td>\n",
       "      <td>Halo #sobatbmkgyia...\\nBerikut Kami Sampaikan ...</td>\n",
       "      <td>[sobatbmkgyia, infobmkg, infobmkgyia, laporanc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp      keyword        date             user  \\\n",
       "0   2023-01-14  bandara yia  2023-01-13    midfieldeer14   \n",
       "1   2023-01-14  bandara yia  2023-01-13      infobmkgyia   \n",
       "2   2023-01-14  bandara yia  2023-01-13         yosanaa_   \n",
       "3   2023-01-14  bandara yia  2023-01-13      Minariiiing   \n",
       "4   2023-01-14  bandara yia  2023-01-13  sewamobilmurah9   \n",
       "5   2023-01-14  bandara yia  2023-01-13     annipusphyta   \n",
       "6   2023-01-14  bandara yia  2023-01-13      stefanaezer   \n",
       "7   2023-01-14  bandara yia  2023-01-13       CecanUtami   \n",
       "8   2023-01-14  bandara yia  2023-01-13           KAI121   \n",
       "9   2023-01-14  bandara yia  2023-01-13           jhnhpt   \n",
       "10  2023-01-14  bandara yia  2023-01-13      infobmkgyia   \n",
       "\n",
       "                                                tweet  \\\n",
       "0   Ada yang mau kerja di bandara lur khusus cewek...   \n",
       "1   Hai #sobatbmkgyia,\\nBerikut kami sampaikan Pra...   \n",
       "2   Kenapa bandara yia jauh banget jadinya harus b...   \n",
       "3   Bandara. \\nYIA Kulon Progo mantep sih. Viewnya...   \n",
       "4   Ready city car matic manual\\nBiar bisa sat set...   \n",
       "5   Parkir mahal di Diy jatuh pada parkir vip band...   \n",
       "6   @KompasTV Dari bukan Jakarta Jogja, tp Tangera...   \n",
       "7               berapa harga tiket kereta bandara yia   \n",
       "8   @zeuschlad Selamat pagi Kak. Perjalanan KA Ban...   \n",
       "9   @UGM_FESS dari Jakarta ke Bandara juga perlu k...   \n",
       "10  Halo #sobatbmkgyia...\\nBerikut Kami Sampaikan ...   \n",
       "\n",
       "                                             hashtags  \\\n",
       "0                                                   0   \n",
       "1   [sobatbmkgyia, infobmkg, infobmkgyia, prakiraa...   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4   [rentalmobiljogja, sewamobiljogja, rentalmobil...   \n",
       "5                                                   0   \n",
       "6                                                   0   \n",
       "7                                                   0   \n",
       "8                                                   0   \n",
       "9                                                   0   \n",
       "10  [sobatbmkgyia, infobmkg, infobmkgyia, laporanc...   \n",
       "\n",
       "                                             mentions  likeCount  \\\n",
       "0                                                   0          8   \n",
       "1                                                   0          1   \n",
       "2                                                   0          0   \n",
       "3                                                   0          0   \n",
       "4                                                   0          0   \n",
       "5                                                   0          0   \n",
       "6                      [https://twitter.com/KompasTV]          0   \n",
       "7                                                   0          0   \n",
       "8   [https://twitter.com/zeuschlad, https://twitte...          0   \n",
       "9                      [https://twitter.com/UGM_FESS]          0   \n",
       "10                                                  0          0   \n",
       "\n",
       "    retweetCount  replyCount  popularityScore sentiment  \n",
       "0              5           8         7.000000  Positive  \n",
       "1              0           0         0.333333  Positive  \n",
       "2              0           0         0.000000   Neutral  \n",
       "3              0           0         0.000000  Positive  \n",
       "4              0           0         0.000000  Positive  \n",
       "5              0           0         0.000000  Positive  \n",
       "6              0           0         0.000000   Neutral  \n",
       "7              0           0         0.000000   Neutral  \n",
       "8              0           1         0.333333  Positive  \n",
       "9              0           0         0.000000   Neutral  \n",
       "10             0           0         0.000000   Neutral  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['timestamp','date']] = df[['timestamp','date']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = df.to_json(\"./test_data/json.json\",orient='records')\n",
    "apid = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = requests.post(url, json = api)\n",
    "\n",
    "# print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in apid:\n",
    "    dicts ={\n",
    "        'dateGet':i['timestamp'],\n",
    "        'keyword':i['keyword'],\n",
    "        'contentDate':i['date'],\n",
    "        'username':i['user'],\n",
    "        'tweet':i['tweet'],\n",
    "        'hashtags':i['hashtags'],\n",
    "        'mentions':i['mentions'],\n",
    "        'likeCount':i['likeCount'],\n",
    "        'retweetCount':i['retweetCount'],\n",
    "        'replyCount':i['replyCount'],\n",
    "        'popularityScore':i['popularityScore'],\n",
    "        'sentiment':i['sentiment'],\n",
    "        'topic':topic\n",
    "        }\n",
    "    # print(dicts)\n",
    "    c = requests.post('{}/post'.format(APIurl),dicts )\n",
    "    print(c)\n",
    "\n",
    "update(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanData[['Tweet', 'Result Prediction', 'text_preprocessed']].to_csv('pemilu.csv')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "872e9ac453f67b7e35588ebe4d602923bc34b4c5daddde36c325676c5fe52d29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
